document.addEventListener('DOMContentLoaded', () => {
const quizData = [
    // موضوع اول: مبانی هوش مصنوعی
    {"question": "هوش مصنوعی (AI) چیست؟", "correct_answer": "شاخه ای از علوم کامپیوتر که به توسعه سیستمهایی می پردازد که قادر به انجام وظایف نیازمند هوش انسانی هستند ", "incorrect_answers": ["مجموعه ای از الگوریتم ها که صرفاً برای پردازش داده های عددی طراحی شده اند ", "فناوری ای که فقط برای رباتها و ماشین های فیزیکی کاربرد دارد ", "روشی برای ذخیره سازی داده ها در پایگاه های داده بزرگ "]},
    {"question": "کدام یک از موارد زیر نمونه ای از یادگیری نظارت شده (Supervised Learning) است؟", "correct_answer": "دسته بندی ایمیلها به اسپم و غیر اسیم با استفاده از داده های برچسب خورده ", "incorrect_answers": ["کشف الگوهای پنهان در داده های بدون برچسب ", "یادگیری از طریق تعامل مستقیم با محیط بدون داده های آموزشی ", "تولید داده های جدید بر اساس نمونه های موجود بدون استفاده از برچسب "]},
    {"question": "تفاوت اصلی بین یادگیری نظارت شده و یادگیری بدون نظارت چیست؟", "correct_answer": "در یادگیری نظارت شده داده ها دارای برچسب هستند و مدل بر اساس آنها آموزش میبیند ولی در یادگیری بدون نظارت داده ها برچسب ندارند ", "incorrect_answers": ["یادگیری بدون نظارت فقط برای داده های متنی کاربرد دارد ولی یادگیری نظارت شده برای داده های عددی ", "یادگیری نظارت شده به صورت خودکار انجام میشود ولی یادگیری بدون نظارت نیاز به دخالت انسان دارد ", "یادگیری بدون نظارت همیشه دقیق تر از یادگیری نظارت شده است "]},
    {"question": "کدام الگوریتم زیر معمولاً برای مسائل طبقه بندی استفاده می شود؟", "correct_answer": "ماشین بردار پشتیبان (SVM) ", "incorrect_answers": ["الگوریتم خوشه بندی K-Means ", "الگوریتم کاهش ابعاد PCA ", "الگوریتم ژنتیک "]},
    {"question": "در حوزه هوش مصنوعی منظور از شبکه عصبی مصنوعی چیست؟", "correct_answer": "مدلی الهام گرفته از ساختار مغز انسان که از لایه هایی از نورونهای مصنوعی تشکیل شده است ", "incorrect_answers": ["مجموعه ای از قوانین منطقی که به صورت دستی نوشته شده اند ", "الگوریتمی برای ذخیره سازی داده ها در پایگاه داده های توزیع شده ", "سخت افزاری برای افزایش سرعت پردازش کامپیوتر "]},
    {"question": "کدام یک از موارد زیر نمونه ای از یادگیری تقویتی (Reinforcement Learning) است؟", "correct_answer": "آموزش ربات برای یادگیری حرکت در محیط با دریافت پاداش یا جریمه ", "incorrect_answers": ["دسته بندی تصاویر با استفاده از داده های برچسب خورده ", "خوشه بندی داده های بدون برچسب برای کشف ساختار ", "تولید متن با استفاده از مدلهای زبانی "]},
    {"question": "کدام مفهوم در هوش مصنوعی به معنای توانایی مدل در تعمیم دادن به داده های جدید و ناشناخته است؟", "correct_answer": "تعمیم پذیری (Generalization) ", "incorrect_answers": ["بیش برازش (Overfitting) ", "کم برازش (Underfitting) ", "یادگیری عمیق (Deep Learning) "]},
    {"question": "در یادگیری ماشین منظور از ویژگی (Feature) چیست؟", "correct_answer": "هر نوع داده یا خصوصیتی که برای آموزش مدل استفاده میشود", "incorrect_answers": ["خروجی نهایی مدل پس از آموزش", "الگوریتمی که برای آموزش مدل به کار می رود", "داده های ورودی خام بدون پردازش"]},
    {"question": "کدام یک از موارد زیر نمونه ای از داده های ساختار یافته است؟", "correct_answer": "جدول اطلاعات مشتریان با ستونهای مشخص مانند نام سن و آدرس ", "incorrect_answers": ["متنهای آزاد و بدون قالب مشخص ", "تصاویر و ویدئوها ", "صداهای ضبط شده "]},
    {"question": "در هوش مصنوعی منظور از یادگیری عمیق (Deep Learning) چیست؟", "correct_answer": "شاخه ای از یادگیری ماشین که از شبکه های عصبی با چندین لایه برای استخراج ویژگیهای پیچیده استفاده می کند ", "incorrect_answers": ["الگوریتمهای ساده یادگیری ماشین بدون استفاده از شبکه های عصبی ", "یادگیری بر اساس قواعد منطقی و برنامه نویسی صریح ", "استفاده از داده های کم برای آموزش مدلهای ساده "]},

    // موضوع دوم: مدلهای زبانی بزرگ - (LLMS)
    {"question": "مدلهای زبانی بزرگ (LLMS) چه ویژگی اصلی دارند؟", "correct_answer": "توانایی درک تولید و پاسخگویی به زبان انسانی با استفاده از شبکه های عصبی عمیق و میلیاردها پارامتر ", "incorrect_answers": ["مدلهایی که تنها برای ترجمه ماشینی طراحی شده و محدود به زبانهای خاص هستند ", "مدلهایی که صرفاً بر اساس قواعد دستوری و قوانین زبان شناسی ساخته شده اند ", "مدلهایی که فقط برای پردازش داده های ساختار یافته و عددی کاربرد دارند "]},
    {"question": "معماری پایه مدلهای زبانی بزرگ چیست و چه مزیتی دارد؟", "correct_answer": "معماری ترنسفورمر با مکانیزم توجه که امکان پردازش توالی های طولانی و درک روابط پیچیده را فراهم می کند ", "incorrect_answers": ["شبکه های عصبی بازگشتی (RNN) که سرعت پردازش بالاتری نسبت به ترنسفورمرها دارند ", "شبکه های عصبی کانولوشنی (CNN) که برای پردازش تصاویر بهینه شده اند ", "مدلهای خطی ساده که برای پردازش زبان طبیعی کافی هستند "]},
    {"question": "منظور از پیش آموزش (Pre-training) در LLM چیست؟", "correct_answer": "آموزش مدل روی مجموعه داده های بزرگ و بدون برچسب برای یادگیری الگوهای عمومی زبان ", "incorrect_answers": ["آموزش مدل فقط روی داده های برچسب خورده برای وظایف خاص ", "آموزش مدل روی داده های کوچک و تخصصی برای افزایش دقت ", "آموزش مدل با داده های تصادفی بدون ساختار مشخص "]},
    {"question": "ریز آموزی (Fine-tuning) در مدلهای زبانی بزرگ چه کاربردی دارد؟", "correct_answer": "بهینه سازی مدل پیش آموزش دیده روی داده های تخصصی و برچسب خورده برای وظایف خاص ", "incorrect_answers": ["آموزش مدل از ابتدا با داده های جدید بدون استفاده از مدل پیش آموزش دیده ", "کاهش تعداد پارامترهای مدل برای افزایش سرعت اجرا ", "حذف لایه های توجه برای ساده سازی مدل "]},
    {"question": "کدام عبارت بهترین توصیف برای مکانیسم توجه (Attention) در مدلهای ترنسفورمر است؟", "correct_answer": "روشی که به مدل اجازه میدهد به بخشهای مختلف ورودی با وزنهای متفاوت توجه کند و روابط بین کلمات را بهتر درک نماید ", "incorrect_answers": ["الگوریتمی برای کاهش تعداد پارامترهای مدل ", "تکنیکی برای افزایش سرعت پردازش مدل با کاهش دقت ", "روشی برای حذف داده های غیر ضروری از مجموعه آموزش "]},
    {"question": "منظور از توهم زایی (Hallucination) در مدلهای زبانی بزرگ چیست؟", "correct_answer": "تولید پاسخهای نادرست یا غیر واقعی توسط مدل حتی زمانی که داده های ورودی صحیح است ", "incorrect_answers": ["عدم توانایی مدل در تولید پاسخ به دلیل کمبود داده ", "تکرار مکرر یک پاسخ مشابه بدون تغییر در محتوا ", "تولید پاسخهای بسیار کوتاه و ناقص به دلیل محدودیت طول ورودی "]},
    {"question": "برای کنترل تنوع و خلاقیت پاسخهای مدلهای زبانی کدام پارامتر تنظیم میشود؟", "correct_answer": "دمای نمونه برداری (Temperature) که با افزایش آن پاسخ ها متنوع تر و خلاقانه تر میشوند ", "incorrect_answers": ["طول توالی ورودی که فقط بر سرعت تأثیر دارد ", "تعداد لایه های مدل که به طور مستقیم تنوع پاسخ را کنترل نمی کند ", "نرخ یادگیری که مربوط به آموزش مدل است نه تولید پاسخ "]},
    {"question": "کدام روش برای بهبود ایمنی و جلوگیری از تولید محتوای نامناسب توسط LLM کاربرد دارد؟", "correct_answer": "اعمال فیلترهای محتوا و تنظیمات ایمنی (Safety Filters) در مرحله پس پردازش خروجی ", "incorrect_answers": ["حذف مکانیزم توجه برای کاهش پیچیدگی مدل ", "افزایش دمای نمونه برداری برای تنوع بیشتر که ممکن است ریسک تولید محتوای نامناسب را افزایش دهد ", "کاهش تعداد پارامترهای مدل بدون بررسی عملکرد "]},
    {"question": "کدام گزینه بهترین توصیف برای پنجره زمینه (Context Window) در مدلهای زبانی بزرگ است؟", "correct_answer": "محدوده ای از توکن ها که مدل در یک زمان میتواند پردازش و به آن توجه کند", "incorrect_answers": ["تعداد كل بارامترهای مدل که بر حجم مدل تأثیر دارد", "تعداد لایه های مدل که بر عمق شبکه تأثیرگذار است ", "سرعت پردازش مدل در سخت افزارهای مختلف "]},
    {"question": "کدام عامل بیشترین تأثیر را در کیفیت و دقت مدلهای زبانی بزرگ دارد؟", "correct_answer": "کیفیت، تنوع و حجم داده های آموزشی و معماری مدل به همراه تنظیمات بهینه سازی", "incorrect_answers": ["سرعت پردازش مدل بدون توجه به داده های آموزشی", "تعداد دفعات اجرای مدل بدون تغییر در داده ها", "حجم حافظه مصرفی مدل که به تنهایی کیفیت را تضمین نمیکند"]},

    // موضوع سوم: مدلهای زبانی بزرگ - مبانی
    {"question": "کدام معماری زیر بنیاد اصلی مدلهای زبانی بزرگ (LLM) مدرن محسوب می شود؟", "correct_answer": "معماری Transformer مبتنی بر مکانیزم توجه ", "incorrect_answers": ["شبکه های عصبی بازگشتی (RNN) با حافظه کوتاه مدت ", "ماشینهای بردار پشتیبان (SVM) برای طبقه بندی متن ", "مدلهای مارکوف پنهان (HMM) برای پیش بینی دنباله ها "]},
    {"question": "هدف اصلی لایه های توجه چند سرانه (Multi-Head Attention) در Transformer چیست؟", "correct_answer": "استخراج وابستگیهای معنایی بین توکن ها از طریق ترکیب اطلاعات از فضا بردارهای مختلف", "incorrect_answers": ["کاهش ابعاد داده های ورودی برای صرفه جویی در محاسبات", "حذف نویز از سیگنالهای متنی با استفاده از فیلترهای خطی", "افزایش سرعت پردازش با موازی سازی عملیات ریاضی"]},
    {"question": "فرآیند توکن سازی (Tokenization) در مدلهای زبانی بزرگ عمدتاً چه کاری انجام می دهد؟", "correct_answer": "تبدیل متن به دنباله ای از اعداد قابل پردازش توسط مدل ", "incorrect_answers": ["فشرده سازی داده های متنی برای ذخیره سازی کارآمد ", "شناسایی خودکار خطاهای املایی در متن ورودی ", "ترجمه متون به زبانهای مختلف برای آموزش چند زبانه "]},
    {"question": "مکانیزم Positional Encoding در معماری Transformer چه نقشی ایفا می کند؟", "correct_answer": "ارائه اطلاعات موقعیتی توکن ها در دنباله ورودی بدون نیاز به ترتیب پردازش ", "incorrect_answers": ["نرمالیزه کردن مقادیر خروجی لایه ها برای جلوگیری از انفجار گرادیان ", "افزایش مصنوعی حجم داده های آموزشی با تولید متن مشابه ", "فیلتر کردن توکنهای نامربوط از طریق تحلیل آماری "]},
    {"question": "کدام لایه در معماری Transformer بیشترین تعداد پارامترهای آموزش پذیر را شامل میشود؟", "correct_answer": "لایه های Feed-Forward با ابعاد میانی بزرگ ", "incorrect_answers": ["لایه های نرمالیزاسیون (LayerNorm) برای پایداری آموزش ", "لایه های توکن سازی اولیه برای تبدیل متن به بردار ", "لایه های Dropout برای جلوگیری از بیش برازش "]},
    {"question": "تفاوت اصلی بین مدلهای Encoder Only و Decoder-Only در چیست؟", "correct_answer": "مدلهای Encoder-Only برای تولید متن مناسب نیستند در حالی که Decoder-Only برای این منظور بهینه شده اند ", "incorrect_answers": ["مدلهای Decoder-Only از توجه یکطرفه استفاده میکنند اما Encoder-Only توجه دوسویه دارد ", "مدلهای Encoder-Only فقط برای ترجمه ماشینی کاربرد دارند ", "مدل های Decoder-Only قادر به پردازش متون طولانی نیستند "]},
    {"question": "مفهوم اتصال باقیمانده (Residual Connection) در Transformer چه مشکلی را حل میکند؟", "correct_answer": "جلوگیری از ناپدید شدن گرادیانها در لایه های عمیق از طریق جمع کردن ورودی و خروجی", "incorrect_answers": ["کاهش مصرف حافظه با حذف پارامترهای زائد", "افزایش دقت محاسبات ممیز شناور در پردازنده های گرافیکی", "بهبود کیفیت توکن سازی با افزودن اطلاعات موقعیتی "]},
    {"question": "کدام یک از موارد زیر نمونه ای از مدلهای زبانی مبتنی بر معماری Decoder-Only است؟", "correct_answer": "GPT-4 با توانایی تولید متن به صورت خودرگرسیونی", "incorrect_answers": ["BERT با قابلیت درک متن از طریق توجه دوسویه", "T5 با معماری Encoder-Decoder برای ترجمه ماشینی", "RoBERTa با بهینه سازی برای وظایف طبقه بندی متن"]},
    {"question": "هدف از استفاده از لایه های نرمالیزاسیون (Layer Norm) در Transformer چیست؟", "correct_answer": "ثابت نگه داشتن میانگین و واریانس خروجی لایه ها برای پایداری آموزش ", "incorrect_answers": ["افزایش غیر خطی بودن محاسبات برای بهبود دقت مدل ", "کاهش ابعاد بردارهای توکن برای صرفه جویی در فضای ذخیره سازی ", "شناسایی خودکار توکنهای پرت در دنباله ورودی "]},
    {"question": "کدام ویژگی زیر مهمترین مزیت معماری Transformer نسبت به RNN ها محسوب می شود؟", "correct_answer": "توانایی پردازش موازی تمام توکنهای ورودی به جای پردازش ترتیبی ", "incorrect_answers": ["نیاز به داده های آموزشی کمتر برای رسیدن به دقت مشابه ", "عدم نیاز به توکن سازی اولیه برای تبدیل متن به اعداد ", "حذف کامل نیاز به تنظیم دستی پارامترهای مدل "]},

    // موضوع چهارم: مدلهای زبانی بزرگ - پیشرفته
    {"question": "برای بهبود عملکرد یک مدل زبانی در تولید متن خلاقانه و متنوع کدام روش معمولاً مؤثرتر است؟", "correct_answer": "افزایش دمای نمونه برداری (Temperature) در زمان تولید متن ", "incorrect_answers": ["کاهش تعداد لایه های مدل ", "استفاده از حجم کمتری از داده های آموزشی ", "حذف مکانیزم توجه از معماری مدل "]},
    {"question": "اگر بخواهید یک مدل زبانی را برای درک بهتر متنهای حقوقی فاین تون کنید کدام رویکرد مناسب تر است؟", "correct_answer": "آموزش مدل روی مجموعه ای از متون حقوقی با برچسبهای دقیق ", "incorrect_answers": ["استفاده از یک مدل عمومی بدون تغییر ", "حذف لایه های نرمالیزاسیون از مدل ", "محدود کردن مدل به پردازش متن های کوتاه "]},
    {"question": "برای کاهش مشکلات توهم زایی (Hallucination) در مدلهای زبانی کدام روش عملی پیشنهاد میشود؟", "correct_answer": "استفاده از تکنیکهای Retrieval-Augmented Generation (RAG) برای ارجاع به منابع معتبر ", "incorrect_answers": ["افزایش تعداد پارامترهای مدل ", "حذف مرحله توکن سازی از فرآیند پردازش ", "کاهش دمای نمونه برداری به صفر "]},
    {"question": "در فاین تونینگ یک مدل زبانی کدام مرحله برای جلوگیری از بیش برازش (Overfitting) ضروری است؟", "correct_answer": "تقسیم داده ها به مجموعه های آموزشی، اعتبار سنجی و آزمایش ", "incorrect_answers": ["استفاده از تمام دادهها برای آموزش مدل ", "آموزش مدل در یک مرحله و بدون ارزیابی ", "حذف لایه های Dropout از مدل "]},
    {"question": "اگر مدل شما در پاسخ به سوالات چند گزینه ای دقت کمی دارد کدام راهکار عملی برای بهبود آن پیشنهاد میشود؟", "correct_answer": "افزودن نمونه های آموزشی متنوع و شبیه به سوالات هدف ", "incorrect_answers": ["کاهش تعداد پارامترهای مدل ", "حذف لایه های توجه از معماری ", "استفاده از مدلهای کوچکتر و کم حجم تر "]},
    {"question": "برای ارزیابی کیفیت پاسخهای یک مدل زبانی کدام روش عملی تر است؟", "correct_answer": "استفاده از معیارهای چندگانه مانند دقت، تنوع و خوانایی پاسخها ", "incorrect_answers": ["ارزیابی تنها بر اساس سرعت پاسخگویی مدل ", "بررسی تعداد بارامترهای مدل ", "ارزیابی بر اساس حجم داده های آموزشی "]},
    {"question": "اگر مدل زبانی شما در تولید متنهای بلند دچار مشکل قطع شدن ناگهانی متن میشود کدام راهکار عملی پیشنهاد میشود؟", "correct_answer": "تنظیم پارامترهای طول دنباله و استفاده از مکانیزمهای تولید متن چند مرحله ای ", "incorrect_answers": ["کاهش دمای نمونه برداری به صفر ", "حذف لایه های Feed-Forward از مدل ", "استفاده از مدلهای کوچکتر "]},
    {"question": "برای کاهش مصرف منابع محاسباتی در فاین تونینگ مدلهای بزرگ کدام روش مناسب تر است؟", "correct_answer": "استفاده از تکنیکهای LoRA یا QLoRA برای بهینه سازی پارامترها ", "incorrect_answers": ["آموزش تمام پارامترهای مدل بدون تغییر ", "حذف لایه های نرمالیزاسیون ", "کاهش تعداد توکن های ورودی به مدل "]},
    {"question": "اگر بخواهید مدل زبانی شما در پاسخ به سوالات چند زبانه عملکرد بهتری داشته باشد کدام راهکار عملی پیشنهاد میشود؟", "correct_answer": "آموزش یا فاین تونینگ مدل روی داده های چند زبانه با برچسب دقیق ", "incorrect_answers": ["محدود کردن مدل به پردازش یک زبان خاص ", "حذف مکانیزم توجه چند سرانه ", "کاهش تعداد پارامترهای مدل "]},
    {"question": "برای افزایش سرعت پاسخگویی مدل زبانی در محیط عملیاتی کدام روش مؤثرتر است؟", "correct_answer": "استفاده از تکنیکهای کمینه سازی مدل (Quantization) و بهینه سازی برای سخت افزار هدف ", "incorrect_answers": ["افزایش تعداد پارامترهای مدل ", "حذف لایه های نرمالیزاسیون ", "کاهش تعداد نمونه های آموزشی "]},

    // موضوع پنجم: پرامیت نویسی
    {"question": "برای طراحی یک پرامیت مؤثر جهت تولید پاسخهای دقیق در مدلهای زبانی کدام نکته کلیدی باید رعایت شود؟", "correct_answer": "مشخص و واضح بودن هدف پرامیت و ارائه زمینه کافی برای مدل ", "incorrect_answers": ["استفاده از جملات کوتاه و خلاصه بدون جزئیات زیاد ", "به کار بردن اصطلاحات تخصصی بدون توضیح بیشتر ", "استفاده از جملات باز و کلی برای افزایش خلاقیت مدل "]},
    {"question": "هنگام نوشتن پرامپتی برای مدل زبانی که میخواهید یک متن رسمی و حرفه ای تولید کند کدام گزینه بهترین روش است؟", "correct_answer": "درخواست صریح برای نوشتن به سبک رسمی و استفاده از عبارات تخصصی مرتبط ", "incorrect_answers": ["استفاده از زبان رسمی اما بدون ارائه نمونه های مشخص ", "نوشتن پرامیت با جملات ساده و غیر رسمی برای انعطاف بیشتر ", "استفاده از اصطلاحات عامیانه همراه با جملات رسمی "]},
    {"question": "اگر مدل زبانی پاسخهای نامرتبط یا خارج از موضوع میدهد کدام اقدام عملی برای بهبود پرامیت پیشنهاد میشود؟", "correct_answer": "افزودن محدودیتها و دستورالعملهای دقیق تر در پرامیت ", "incorrect_answers": ["کوتاه کردن پرامیت و حذف جزئیات اضافی ", "استفاده از پرامیتهای باز برای تحریک خلاقیت مدل ", "اضافه کردن سوالات فرعی در پرامیت برای راهنمایی بیشتر"]},
    {"question": "در پرامپت نویسی استفاده از مثالهای نمونه (Few-shot learning) چه تأثیری دارد؟", "correct_answer": "کمک به مدل برای درک بهتر قالب پاسخ مورد انتظار و افزایش دقت خروجی ", "incorrect_answers": ["افزایش طول پرامیت که ممکن است باعث کاهش سرعت شود ", "ارائه نمونه های نامرتبط که میتواند مدل را سردرگم کند ", "جایگزینی کامل نیاز به داده های آموزشی برای مدل "]},
    {"question": "برای بهینه سازی پرامیت جهت تولید پاسخهای خلاصه و کوتاه کدام روش کاربردی است؟", "correct_answer": "درخواست صریح برای خلاصه سازی و محدود کردن تعداد کلمات پاسخ ", "incorrect_answers": ["استفاده از جملات پیچیده برای هدایت مدل به پاسخ های دقیق ", "ارائه داده های متنوع برای افزایش دامنه پاسخها ", "حذف هرگونه دستور العمل مربوط به طول پاسخ "]},
    {"question": "در پرامپت نویسی برای مدلهای زبانی چرا باید از اصطلاحات مبهم یا دو پهلو پرهیز کرد؟", "correct_answer": "باعث سردرگمی مدل و تولید پاسخهای نامشخص یا نادرست میشود ", "incorrect_answers": ["ممکن است مدل را به تولید پاسخهای کوتاه تر ترغیب کند ", "به مدل اجازه میدهد خلاقیت بیشتری در پاسخ داشته باشد ", "باعث افزایش سرعت پردازش مدل میشود "]},
    {"question": "هنگام استفاده از پرامیت برای استخراج اطلاعات خاص از متن کدام ویژگی باید در پرامیت وجود داشته باشد؟", "correct_answer": "تعیین دقیق نوع اطلاعات مورد نظر و قالب خروجی مورد انتظار ", "incorrect_answers": ["ارائه سوالات کلی برای پوشش دادن تمام جنبه ها ", "درخواست پاسخ آزاد بدون محدودیت قالب ", "حذف هرگونه محدودیت برای افزایش خلاقیت مدل "]},
    {"question": "اگر بخواهید پرامپتی بنویسید که مدل به صورت مرحله به مرحله مسئله ای را حل کند کدام روش مناسب تر است؟", "correct_answer": "درخواست صریح برای ارائه مراحل حل به صورت گام به گام ", "incorrect_answers": ["درخواست پاسخ نهایی به همراه خلاصه ای از مراحل ", "استفاده از پرامیتهای کوتاه و کلی ", "ارائه چند مسئله مختلف در یک پرامیت برای صرفه جویی در زمان "]},
    {"question": "در چه شرایطی استفاده از پرامپتهای چند مرحله ای (Chain-of-Thought) توصیه می شود؟", "correct_answer": "زمانی که مسئله پیچیده و نیازمند تحلیل دقیق و استدلال است ", "incorrect_answers": ["زمانی که پاسخ کوتاه و مستقیم مورد نیاز است ", "زمانی که داده های ورودی بسیار کوتاه هستند ", "زمانی که مدل باید فقط اطلاعات عمومی را بازیابی کند "]},
    {"question": "برای تست کیفیت پرامپت نوشته شده کدام روش عملی مؤثرتر است؟", "correct_answer": "اجرای پرامیت روی نمونه های مختلف داده و بررسی دقت و مرتبط بودن پاسخ ها ", "incorrect_answers": ["اعتماد به اولین پاسخ مدل بدون ارزیابی بیشتر ", "استفاده از پرامیت فقط روی داده های آموزشی محدود ", "حذف بازخورد کاربران از فرآیند ارزیابی "]},

    // موضوع ششم: n8n و اتوماسیون
    {"question": "برای شروع ساخت یک گردش کار (Workflow) در n8n، اولین قدم عملی چیست؟", "correct_answer": "انتخاب یک تریگر (Trigger) مناسب برای شروع خودکار گردش کار", "incorrect_answers": ["اضافه کردن چندین نود (Node) بدون ترتيب خاص", "نوشتن کدهای جاوا اسکریپت قبل از تعریف گردش کار", "اتصال مستقیم به پایگاه داده بدون استفاده از تریگر"]},
    {"question": "در n8n، برای اتصال به یک API خارجی و دریافت داده کدام نود معمولاً استفاده می شود؟", "correct_answer": "HTTP Request برای ارسال درخواست های RESTful ", "incorrect_answers": ["Function برای اجرای کد جاوا اسکریپت ", "Set برای تعریف متغیرهای داخلی ", "Merge برای ترکیب داده ها "]},
    {"question": "چگونه می توان در n8n داده های ورودی را قبل از ارسال به نود بعدی تغییر داد؟", "correct_answer": "استفاده از نود Function برای نوشتن اسکریپتهای پردازش داده ", "incorrect_answers": ["تغییر مستقیم در پایگاه داده متصل به گردش کار ", "اضافه کردن نود Trigger برای تغییر داده ها ", "استفاده از نود Merge برای ادغام داده ها "]},
    {"question": "برای اجرای گردش کار به صورت زمان بندی شده در n8n، کدام نود باید به عنوان تریگر انتخاب شود؟", "correct_answer": "Cron برای تعریف زمان بندی های دوره ای ", "incorrect_answers": ["Webhook برای دریافت درخواست های HTTP ", "HTTP Request برای ارسال داده ها ", "Start برای شروع دستی گردش کار "]},
    {"question": "اگر بخواهید در n8n خطاهای یک نود را مدیریت کنید بهترین روش چیست؟", "correct_answer": "استفاده از نود Error Trigger برای واکنش به خطاها ", "incorrect_answers": ["حذف نودهای مشکل دار از گردش کار ", "اجرای مجدد کل گردش کار بدون تغییر ", "غیر فعال کردن لاگهای خطا "]},
    {"question": "برای ارسال داده ها به یک سرویس ایمیل در n8n، کدام نود مناسب است؟", "correct_answer": "Email Send برای ارسال ایمیل با تنظیمات SMTP ", "incorrect_answers": ["HTTP Request برای ارسال داده ها ", "Function برای نوشتن کد ارسال ایمیل ", "Merge برای ترکیب داده ها "]},
    {"question": "در n8n، برای ذخیره موقت داده ها در طول گردش کار کدام روش کاربردی تر است؟", "correct_answer": "استفاده از نود Set برای تعریف و ذخیره متغیرهای موقت ", "incorrect_answers": ["ذخیره مستقیم در پایگاه داده خارجی ", "ارسال داده ها به نود HTTP Request ", "حذف داده ها پس از هر مرحله "]},
    {"question": "چگونه میتوان در n8n یک گردش کار را به صورت شرطی (Conditional) اجرا کرد؟", "correct_answer": "استفاده از نود If برای تعریف شرطهای منطقی ", "incorrect_answers": ["اضافه کردن چندین نود Start به گردش کار ", "اجرای گردش کار در چندین سرور به صورت موازی ", "استفاده از نود Merge برای ترکیب شرطها "]},
    {"question": "در زمان طراحی گردش کار در n8n، بهترین روش برای اشکال زدایی (Debug) چیست؟", "correct_answer": "استفاده از حالت اجرای مرحله به مرحله و مشاهده خروجی هر نود ", "incorrect_answers": ["اجرای کل گردش کار بدون توقف و بررسی لاگها بعد از اتمام ", "حذف نودهای مشکوک و اجرای مجدد گردش کار ", "غیر فعال کردن نودهای غیر ضروری بدون بررسی خروجی "]},
    {"question": "برای به اشتراک گذاری یک گردش کار ساخته شده در n8n با دیگران کدام روش عملی مناسب است؟", "correct_answer": "صادر کردن (Export) فایل JSON گردش کار و ارسال آن ", "incorrect_answers": ["ارسال دسترسی مستقیم به سرور n8n بدون محدودیت ", "کپی برداری از کدهای جاوا اسکریپت هر نود به صورت جداگانه ", "بازنویسی گردش کار از ابتدا توسط هر فرد دیگر "]},

    // موضوع هفتم: Model Context Protocol (MCP)
    {"question": "در استفاده از MCP، برای اتصال یک مدل زبانی به منابع داده خارجی بهترین روش عملی چیست؟", "correct_answer": "تعريف کانکشنهای دقیق و معتبر با استفاده از استانداردهای پروتکل MCP", "incorrect_answers": ["استفاده از کانکشنهای عمومی با تنظیمات پیش فرض برای سرعت بیشتر", "ارسال داده ها به مدل به صورت مستقیم بدون واسطه پروتکل", "بارگذاری داده ها به صورت محلی و انتقال دستی به مدل"]},
    {"question": "برای بهینه سازی عملکرد مدل در MCP، کدام اقدام عملی توصیه میشود؟", "correct_answer": "تنظیم دقیق پارامترهای کانکشن و محدود کردن حجم داده های ورودی ", "incorrect_answers": ["افزایش تعداد منابع داده حتی با وجود داده های غیر مرتبط برای تنوع بیشتر ", "استفاده از داده های بزرگ بدون پیش پردازش برای حفظ اصالت محتوا ", "حذف محدودیتهای دسترسی برای تسهیل جریان داده "]},
    {"question": "هنگام پیاده سازی MCP، کدام روش برای اطمینان از امنیت داده ها مناسب تر است؟", "correct_answer": "استفاده از پروتکلهای رمزنگاری استاندارد و احراز هویت چند مرحله ای", "incorrect_answers": ["رمزنگاری داده ها در سطح انتقال بدون کنترل دسترسی دقیق", "استفاده از فایروال برای محدود کردن دسترسی به سرورها", "ذخیره داده ها در سرورهای امن بدون رمزنگاری انتقال "]},
    {"question": "در MCP، برای مدیریت نسخه های مختلف مدلها و داده ها کدام روش عملی کاربردی است؟", "correct_answer": "استفاده از سیستمهای کنترل نسخه و مستندسازی تغییرات به صورت منظم ", "incorrect_answers": ["ذخیره نسخه ها در پوشه های جداگانه بدون ثبت تغییرات ", "نگهداری نسخه های اصلی بدون نسخه های پشتیبان ", "استفاده از نام گذاری تاریخ دار بدون مستندسازی جزئیات "]},
    {"question": "اگر مدل در MCP به منابع داده پاسخ ندهد بهترین راهکار عملی چیست؟", "correct_answer": "بررسی اتصال شبکه، اعتبار کانکشنها و اجرای مجدد درخواستها ", "incorrect_answers": ["راه اندازی مجدد مدل بدون بررسی اتصال منابع ", "حذف منابع داده مشکل دار و ادامه کار با منابع باقی مانده ", "کاهش حجم داده های ورودی برای کاهش بار شبکه "]},
    {"question": "برای تست صحت عملکرد MCP در یک پروژه کدام روش عملی مناسب تر است؟", "correct_answer": "اجرای تستهای یکپارچه سازی با داده های واقعی و شبیه سازی شده ", "incorrect_answers": ["اجرای مدل با داده های نمونه محدود و بررسی خروجی کلی ", "بررسی کدهای منبع بدون اجرای عملی ", "استفاده از داده های تصادفی برای تست سرعت "]},
    {"question": "هنگام توسعه با MCP، چگونه میتوان از سازگاری داده ها با مدل اطمینان حاصل کرد؟", "correct_answer": "تعریف دقیق فرمت داده ها و اعتبار سنجی ورودیها قبل از ارسال به مدل ", "incorrect_answers": ["استفاده از داده های خام و اصلاح آنها در مرحله بعدی ", "ارسال داده ها بدون بررسی فرمت برای سرعت بیشتر ", "استفاده از داده های نمونه محدود برای تست اولیه "]},
    {"question": "در MCP، برای افزایش قابلیت اطمینان سیستم چه رویکردی عملی پیشنهاد میشود؟", "correct_answer": "پیاده سازی مکانیزمهای پشتیبان گیری و بازیابی خودکار در صورت خطا ", "incorrect_answers": ["اجرای مدل در چند سرور به صورت موازی بدون هماهنگی ", "نادیده گرفتن خطاهای کوچک و ادامه کار ", "محدود کردن تعداد منابع داده برای کاهش پیچیدگی "]},
    {"question": "کدام مورد از مزایای استفاده از MCP در پروژه های هوش مصنوعی است؟", "correct_answer": "تسهیل اتصال مدلها به منابع داده متنوع و مدیریت یکپارچه آنها ", "incorrect_answers": ["کاهش نیاز به تنظیمات مدل در زمان اجرا ", "افزایش سرعت پردازش با کاهش حجم داده ها ", "حذف نیاز به فاین تونینگ مدلها "]},
    {"question": "برای مستندسازی پروژه های مبتنی بر MCP، کدام روش عملی مناسب تر است؟", "correct_answer": "ثبت دقیق تنظیمات کانکشنها، نسخه های مدل و تغییرات داده ها در مستندات پروژه ", "incorrect_answers": ["نگهداری یادداشتهای فنی به صورت پراکنده و غیر ساختاری ", "مستندسازی فقط تغییرات عمده و حذف جزئیات کوچک ", "استفاده از فایلهای متنی ساده بدون قالب بندی مشخص "]},

    // موضوع هشتم: استفاده از مدلهای محلی
    {"question": "برای استفاده بهینه از یک مدل زبانی به صورت محلی کدام اقدام اولیه ضروری است؟", "correct_answer": "نصب و پیکربندی محیط اجرای مدل مطابق با مستندات رسمی ", "incorrect_answers": ["اجرای مدل بدون بررسی پیش نیازهای سخت افزاری ", "استفاده از نسخه های قدیمی مدل بدون به روزرسانی ", "بارگذاری داده های آموزشی به صورت مستقیم در حافظه مدل "]},
    {"question": "هنگام اجرای مدل به صورت محلی چگونه میتوان مصرف منابع سیستم را بهینه کرد؟", "correct_answer": "تنظیم پارامترهای مدل مانند اندازه دسته (batch size) و استفاده از GPU در صورت امکان ", "incorrect_answers": ["اجرای مدل با تنظیمات پیش فرض بدون توجه به سخت افزار ", "کاهش کیفیت داده های ورودی برای کاهش مصرف حافظه ", "استفاده از نسخه های مدل بزرگتر برای دقت بالاتر بدون توجه به منابع "]},
    {"question": "اگر مدل محلی در پردازش متون طولانی دچار کندی شود بهترین راهکار چیست؟", "correct_answer": "تقسیم متن به بخشهای کوچکتر و پردازش مرحله ای آنها ", "incorrect_answers": ["افزایش تعداد لایه های مدل برای بهبود دقت ", "حذف بخشهایی از متن به صورت تصادفی برای کاهش حجم ورودی ", "اجرای مدل روی سیستم با سخت افزار ضعیف تر برای تست "]},
    {"question": "برای به روز رسانی یک مدل محلی با داده های جدید کدام روش عملی مناسب تر است؟", "correct_answer": "انجام فاین تونینگ مدل با داده های جدید و حفظ وزنهای قبلی ", "incorrect_answers": ["جایگزینی کامل مدل با نسخه جدید بدون استفاده از داده های قبلی ", "حذف داده های قدیمی و استفاده صرف از داده های تازه ", "استفاده از مدل اصلی بدون به روز رسانی برای حفظ ثبات "]},
    {"question": "هنگام استفاده از مدل محلی چگونه میتوان از امنیت داده ها اطمینان حاصل کرد؟", "correct_answer": "اجرای مدل در محیط ایزوله و محدود کردن دسترسی به داده ها ", "incorrect_answers": ["اشتراک گذاری داده ها با سرویسهای ابری برای پردازش سریع تر ", "ذخیره داده ها در پوشه های عمومی سیستم ", "استفاده از مدلهای بدون رمزنگاری در محیط باز "]},
    {"question": "در زمان استفاده محلی از مدلهای زبانی بهترین روش برای مدیریت خطاهای ناگهانی چیست؟", "correct_answer": "پیاده سازی لاگ گیری دقیق و بررسی خطاها برای رفع مشکلات ", "incorrect_answers": ["نادیده گرفتن خطاها و ادامه اجرای مدل ", "راه اندازی مجدد سیستم بدون بررسی علت خطا ", "حذف فایلهای مدل برای جلوگیری از بروز خطا "]},
    {"question": "برای افزایش سرعت پاسخگویی مدل محلی کدام گزینه عملی تر است؟", "correct_answer": "استفاده از تکنیکهای کمینه سازی مدل مانند Quantization یا Pruning ", "incorrect_answers": ["افزایش تعداد نمونه های ورودی در هر بار اجرا ", "اجرای مدل روی پردازنده های ضعیف تر برای تست استرس ", "کاهش حافظه رم سیستم برای بهبود عملکرد "]},
    {"question": "اگر مدل محلی شما به دلیل محدودیت سخت افزاری نتواند به خوبی اجرا شود بهترین راهکار چیست؟", "correct_answer": "استفاده از نسخه های سبک تر مدل یا مدلهای بهینه شده برای محیط محلی ", "incorrect_answers": ["افزایش حجم داده های ورودی برای بهبود دقت ", "حذف لایه های حیاتی مدل برای کاهش حجم ", "اجرای مدل در حالت آفلاین بدون اتصال به اینترنت "]},
    {"question": "هنگام اجرای مدل به صورت محلی کدام روش برای ارزیابی عملکرد مدل مناسب تر است؟", "correct_answer": "استفاده از مجموعه داده های آزمایشی استاندارد و مقایسه نتایج با معیارهای دقیق ", "incorrect_answers": ["بررسی خروجی مدل بر روی داده های واقعی بدون معیار ارزیابی ", "اعتماد کامل به نتایج اولیه بدون آزمون مجدد ", "استفاده از داده های آموزشی برای ارزیابی مدل "]},
    {"question": "برای مدیریت نسخه های مختلف مدلهای محلی کدام روش عملی توصیه می شود؟", "correct_answer": "استفاده از سیستمهای کنترل نسخه و مستندسازی تغییرات هر نسخه ", "incorrect_answers": ["ذخیره همه نسخه ها در یک پوشه بدون تفکیک ", "حذف نسخه های قدیمی بدون پشتیبان گیری ", "استفاده از نام گذاری تصادفی برای فایلهای مدل "]},

    // موضوع نهم: LM Studio و ابزارهای مشابه
    {"question": "برای شروع کار با LM Studio جهت اجرای مدلهای زبانی محلی اولین اقدام عملی چیست؟", "correct_answer": "نصب نرم افزار و تنظیم محیط اجرای مدل مطابق با مستندات رسمی ", "incorrect_answers": ["اجرای نرم افزار با تنظیمات پیش فرض و سپس اصلاح تدریجی پیکربندی ", "دانلود مدلها به صورت جداگانه و بارگذاری دستی در نرم افزار ", "اتصال به اینترنت برای دریافت نسخه های به روز بدون نصب اولیه نرم افزار "]},
    {"question": "برای بهبود سرعت اجرای مدل در LM Studio، کدام اقدام عملی مناسب تر است؟", "correct_answer": "فعال سازی استفاده از GPU و تنظیم پارامترهای بهینه مانند batch size ", "incorrect_answers": ["کاهش کیفیت داده های ورودی به منظور کاهش بار محاسباتی ", "استفاده از نسخه های مدل سبک تر بدون تغییر تنظیمات سخت افزاری ", "اجرای مدل در حالت پیش فرض و صرفاً افزایش تعداد هسته های CPU "]},
    {"question": "اگر بخواهید مدل را برای کاربرد خاصی فاینتون کنید بهترین روش چیست؟", "correct_answer": "بارگذاری مجموعه داده های مرتبط و استفاده از قابلیت فاین تونینگ داخلی نرم افزار ", "incorrect_answers": ["استفاده از مدل پیش فرض و تنظیم پارامترهای خروجی برای تطبیق با کاربرد ", "اعمال تغییرات دستی در کد مدل بدون استفاده از داده های جدید ", "کاهش تعداد پارامترهای مدل برای تسریع فرآیند اجرا "]},
    {"question": "هنگام مواجهه با خطا در اجرای مدل بهترین راهکار عملی چیست؟", "correct_answer": "بررسی لاگهای خطا و مراجعه به مستندات برای رفع مشکل ", "incorrect_answers": ["راه اندازی مجدد نرم افزار بدون بررسی دقیق علت خطا ", "حذف مدل و نصب مجدد نرم افزار بدون تحلیل خطا ", "ادامه کار بدون توجه به خطا تا زمان بروز مشکل جدی تر "]},
    {"question": "چگونه میتوان داده های ورودی را قبل از پردازش مدل تغییر داد؟", "correct_answer": "استفاده از ابزارهای داخلی ویرایش داده یا نودهای پردازش داده در محیط نرم افزار ", "incorrect_answers": ["پردازش داده ها در نرم افزارهای جانبی و وارد کردن داده های اصلاح شده ", "تغییر مستقیم فایلهای مدل برای اعمال تغییرات روی داده ها ", "استفاده از داده های خام بدون هیچگونه پیش پردازش "]},
    {"question": "برای به اشتراک گذاری پروژه یا مدل ساخته شده کدام روش مناسب است؟", "correct_answer": "صادر کردن پروژه به فرمت استاندارد و ارسال فایل به دیگر کاربران ", "incorrect_answers": ["اشتراک گذاری پوشه نصب نرم افزار به صورت کامل ", "ارسال کدهای منبع مدل بدون مستندات و تنظیمات محیط ", "بازسازی پروژه توسط هر کاربر به صورت مستقل بدون فایل مشترک "]},
    {"question": "برای کاهش مصرف حافظه در اجرای مدلهای بزرگ چه روشی کاربردی است؟", "correct_answer": "استفاده از تکنیکهای Quantization یا Pruning در تنظیمات نرم افزار ", "incorrect_answers": ["کاهش حجم داده های ورودی به صورت دستی ", "اجرای مدل روی سیستم با حافظه کمتر برای تست کارایی ", "حذف لایه های کلیدی مدل برای کاهش حجم بدون ارزیابی "]},
    {"question": "برای ارزیابی عملکرد مدل در LM Studio، بهترین روش چیست؟", "correct_answer": "استفاده از مجموعه داده های آزمایشی استاندارد و معیارهای ارزیابی دقیق ", "incorrect_answers": ["بررسی خروجی مدل روی داده های واقعی بدون معیار کمی ", "اعتماد به نتایج اولیه بدون آزمونهای تکمیلی ", "ارزیابی صرفاً بر اساس سرعت اجرای مدل "]},
    {"question": "هنگام به روز رسانی مدل کدام روش عملی بهتر است؟", "correct_answer": "پشتیبان گیری از نسخه فعلی و اعمال به روز رسانی کنترل شده ", "incorrect_answers": ["جایگزینی مدل قدیمی با نسخه جدید بدون پشتیبان گیری ", "حذف مدل قدیمی و نصب نسخه جدید به صورت کامل ", "استفاده از نسخه قدیمی برای حفظ ثبات سیستم "]},
    {"question": "برای افزایش امنیت داده ها کدام اقدام عملی توصیه می شود؟", "correct_answer": "اجرای نرم افزار در محیط ایزوله و محدود کردن دسترسی به داده ها و مدلها ", "incorrect_answers": ["اشتراک گذاری داده ها و مدلها با تیم به صورت کنترل شده ", "ذخیره داده ها در پوشه های محافظت نشده برای دسترسی سریع ", "استفاده از مدل ها و داده ها بدون رمزنگاری در محیط های باز "]},

    // موضوع دهم: شبکه های عصبی
    {"question": "در طراحی یک شبکه عصبی نقش لایه های پنهان (Hidden Layers) چیست؟", "correct_answer": "استخراج ویژگیهای پیچیده و انتزاعی از داده های ورودی", "incorrect_answers": ["ذخیره داده های ورودی به صورت خام برای استفاده بعدی", "کاهش ابعاد داده ها بدون تغییر اطلاعات اصلی", "ارسال مستقیم داده ها به خروجی بدون پردازش"]},
    {"question": "کدام تابع فعال سازی (Activation Function) معمولاً برای حل مسئله های طبقه بندی دودویی استفاده میشود؟", "correct_answer": "تابع سیگموید (Sigmoid) به دلیل خروجی بین ۰ و ۱", "incorrect_answers": ["تابع ReLU برای جلوگیری از ناپدید شدن گرادیان ", "تابع تانژانت هیپربولیک (Tanh) برای مقادیر بین ۱- و ۱ ", "تابع خطی برای حفظ مقادیر ورودی "]},
    {"question": "مشکل ناپدید شدن گرادیان (Vanishing Gradient) در کدام نوع شبکه عصبی بیشتر مشاهده می شود؟", "correct_answer": "شبکه های عصبی بازگشتی (RNN) با لایه های عمیق", "incorrect_answers": ["شبکه های عصبی کانولوشنی (CNN) با تعداد کم لایه", "شبکه های عصبی ساده با یک لایه پنهان", "شبکه های عصبی با لایه خروجی خطی"]},
    {"question": "برای جلوگیری از بیش برازش (Overfitting) در شبکه های عصبی کدام روش کاربردی تر است؟", "correct_answer": "استفاده از تکنیک Dropout برای غیر فعال کردن تصادفی نورونها در حین آموزش ", "incorrect_answers": ["افزایش تعداد لایه ها و نورونها برای افزایش دقت ", "استفاده از داده های آموزشی کمتر برای کاهش پیچیدگی ", "حذف لایه های نرمالیزاسیون (Batch Normalization) "]},
    {"question": "در شبکه های عصبی کانولوشنی (CNN)، لایه کانولوشن چه وظیفه ای دارد؟", "correct_answer": "استخراج ویژگیهای محلی از داده های ورودی مانند تصاویر ", "incorrect_answers": ["کاهش ابعاد داده ها به صورت تصادفی ", "ترکیب تمام ویژگی ها به یک مقدار عددی ", "ارسال داده ها به لایه خروجی بدون پردازش "]},
    {"question": "کدام گزینه بهترین توصیف برای مفهوم یادگیری انتقالی (Transfer Learning) در شبکه های عصبی است؟", "correct_answer": "استفاده از مدلهای آموزش دیده قبلی و تنظیم آنها برای مسائل جدید با داده های کمتر ", "incorrect_answers": ["آموزش مدل از ابتدا با داده های جدید و حذف وزنهای قبلی ", "انتقال داده ها از یک مدل به مدل دیگر بدون تغییر وزنها ", "استفاده از داده های مشابه برای آموزش مدلهای مختلف به صورت جداگانه "]},
    {"question": "در فرآیند آموزش شبکه عصبی نقش الگوریتم پس انتشار خطا (Backpropagation) چیست؟", "correct_answer": "محاسبه گرادیان خطا و به روز رسانی وزنها برای بهبود عملکرد مدل", "incorrect_answers": ["تولید داده های جدید برای افزایش حجم مجموعه آموزشی", "کاهش تعداد نورونها در لایه های پنهان", "تنظیم پارامترهای سخت افزاری برای اجرای سریع تر مدل "]},
    {"question": "کدام گزینه بهترین کاربرد شبکه های عصبی بازگشتی (RNN) است؟", "correct_answer": "پردازش داده های ترتیبی مانند متن و سریهای زمانی ", "incorrect_answers": ["تحلیل تصاویر ثابت و تشخیص اشیاء ", "کاهش ابعاد داده های بزرگ ", "طبقه بندی داده های ساختار یافته "]},
    {"question": "در شبکه های عصبی منظور از «پارامترهای آموزش پذیر» چیست؟", "correct_answer": "وزنها و بایاسهایی که در طول آموزش به روز رسانی میشوند", "incorrect_answers": ["داده های ورودی که به مدل داده میشود", "تنظیمات سخت افزاری برای اجرای مدل", "تعداد لایه های شبکه"]},
    {"question": "برای بهبود پایداری و سرعت آموزش شبکه عصبی کدام تکنیک معمولاً استفاده می شود؟", "correct_answer": "استفاده از Batch Normalization برای نرمال سازی ورودی هر لایه ", "incorrect_answers": ["افزایش نرخ یادگیری به مقدار بسیار زیاد ", "حذف لایه های پنهان برای ساده سازی مدل ", "استفاده از داده های آموزشی کمتر برای کاهش زمان آموزش "]},

    // موضوع یازدهم: پردازش زبان طبیعی (NLP)
    {"question": "در پیش پردازش داده های متنی کدام روش برای کاهش ابعاد و حذف کلمات کم اهمیت کاربردی است؟", "correct_answer": "حذف كلمات توقف (Stop Words) برای کاهش نویز داده ها ", "incorrect_answers": ["افزایش تعداد توکن ها برای افزایش دقت مدل ", "جایگزینی تمام کلمات با معادلهای عددی بدون توجه به معنی ", "حذف تمام کلمات کوتاه به صورت تصادفی "]},
    {"question": "کدام تکنیک در NLP برای تبدیل متن به بردارهای عددی قابل استفاده در مدلهای یادگیری ماشین کاربرد دارد؟", "correct_answer": "استفاده از روشهای تعبیه کلمات (Word Embeddings) مانند Word2Vec یا GloVe ", "incorrect_answers": ["حذف تمام علائم نگارشی و اعداد از متن ", "ذخیره متن به صورت فایلهای متنی ساده بدون پردازش ", "استفاده از الگوریتمهای خوشه بندی برای دسته بندی متن "]},
    {"question": "در مدلهای مبتنی بر یادگیری عمیق کدام معماری برای پردازش متنهای طولانی و وابستگیهای دوربرد مناسب تر است؟", "correct_answer": "معماری Transformer با مکانیزم توجه (Attention)", "incorrect_answers": ["شبکه های عصبی کانولوشنی (CNN) ساده", "مدلهای خطی بدون لایه های پنهان", "الگوریتم های درخت تصمیم"]},
    {"question": "برای تشخیص احساسات در متن (Sentiment Analysis)، کدام نوع داده آموزشی اهمیت بیشتری دارد؟", "correct_answer": "داده های برچسب خورده با احساسات مثبت، منفی یا خنثی ", "incorrect_answers": ["داده های خام بدون برچسب ", "داده های متنی با طول بسیار کوتاه بدون زمینه ", "داده های تصویری مرتبط با متن "]},
    {"question": "در پردازش زبان طبیعی منظور از توکن سازی چیست؟", "correct_answer": "تقسیم متن به واحدهای کوچک تر مانند کلمات یا جملات برای پردازش بهتر", "incorrect_answers": ["حذف كلمات غیر ضروری از متن", "تبدیل متن به زبان برنامه نویسی", "ذخیره متن در پایگاه داده"]},
    {"question": "کدام روش برای کاهش ابهام در مدلهای زبانی و بهبود دقت ترجمه ماشینی کاربرد دارد؟", "correct_answer": "استفاده از مدلهای توجه دوسویه (Bidirectional Attention) مانند BERT ", "incorrect_answers": ["افزایش تعداد لایه های مدل بدون تغییر ساختار ", "حذف داده های آموزشی غیر مرتبط ", "استفاده از الگوریتمهای خوشه بندی برای گروه بندی داده ها "]},
    {"question": "در کاربردهای استخراج اطلاعات کدام تکنیک برای شناسایی موجودیتهای نامدار (NER) استفاده می شود؟", "correct_answer": "مدلهای یادگیری عمیق با برچسب گذاری توکن به توکن", "incorrect_answers": ["حذف کلمات کلیدی از متن", "استفاده از الگوریتمهای خوشه بندی بدون برچسب", "ترجمه متن به زبان دیگر و بازگرداندن"]},
    {"question": "برای بهبود کیفیت مدلهای NLP در زبانهای کم منبع کدام رویکرد عملی مؤثر است؟", "correct_answer": "استفاده از یادگیری انتقالی (Transfer Learning) از مدلهای چند زبانه بزرگ ", "incorrect_answers": ["استفاده از داده های محدود بدون پیش پردازش ", "افزایش تعداد لایه های مدل به صورت تصادفی ", "حذف داده های زبانهای دیگر برای تمرکز بر زبان هدف "]},
    {"question": "در پردازش متن کدام تکنیک برای خلاصه سازی خودکار متن کاربرد دارد؟", "correct_answer": "استفاده از مدلهای تولید متن با مکانیزم توجه و فاین توئینگ بر روی داده های خلاصه شده", "incorrect_answers": ["حذف جملات طولانی به صورت دستی", "استفاده از الگوریتمهای خوشه بندی برای گروه بندی کلمات", "تبدیل متن به کدهای باینری"]},
    {"question": "برای ارزیابی عملکرد مدلهای NLP، کدام معیار معمولاً استفاده می شود؟", "correct_answer": "معیارهایی مانند دقت (Accuracy)، یادآوری (Recall) و F1-Score ", "incorrect_answers": ["سرعت اجرای مدل بدون توجه به کیفیت خروجی ", "حجم داده های آموزشی استفاده شده ", "تعداد پارامترهای مدل "]},

    // موضوع دوازدهم: اخلاق در هوش مصنوعی
    {"question": "در طراحی سیستمهای هوش مصنوعی چرا شفافیت (Transparency) اهمیت دارد؟", "correct_answer": "برای اطمینان از اینکه تصمیمات مدل قابل فهم و قابل توضیح برای کاربران باشد ", "incorrect_answers": ["برای افزایش قابلیت بازبینی و تحلیل عملکرد مدل توسط تیم توسعه ", "برای بهبود سرعت پردازش مدل با کاهش پیچیدگی های غیر ضروری ", "برای کاهش هزینه های توسعه با استفاده از ابزارهای ساده تر "]},
    {"question": "کدام اقدام عملی میتواند به کاهش تعصب (Bias) در مدلهای هوش مصنوعی کمک کند؟", "correct_answer": "استفاده از داده های متنوع و نماینده جامعه هدف در آموزش مدل ", "incorrect_answers": ["بازنگری منظم داده ها و به روز رسانی مدل برای اصلاح تعصبات شناسایی شده ", "استفاده از الگوریتمهای تنظیم خودکار برای کاهش اثر داده های نامتوازن ", "افزایش پیچیدگی مدل برای جبران تعصبات داده ها "]},
    {"question": "در صورت کشف خطا یا تبعیض در یک سیستم AI، بهترین رویکرد عملی چیست؟", "correct_answer": "بررسی دقیق علت مشکل و اصلاح داده ها یا الگوریتم ها به سرعت ", "incorrect_answers": ["اطلاع رسانی به ذینفعان و ایجاد برنامه اصلاحی برای رفع مشکل ", "محدود کردن استفاده از سیستم تا زمان رفع کامل مشکل ", "ادامه استفاده از سیستم با نظارت بیشتر بر خروجی ها "]},
    {"question": "چرا حفظ حریم خصوصی کاربران در سیستمهای هوش مصنوعی اهمیت دارد؟", "correct_answer": "برای جلوگیری از سوء استفاده و حفظ اعتماد کاربران به سیستم ", "incorrect_answers": ["برای رعایت قوانین و مقررات مربوط به حفاظت داده ها ", "برای کاهش ریسک افشای اطلاعات حساس و جلوگیری از حملات سایبری ", "برای بهبود کیفیت داده های آموزشی و عملکرد مدل "]},
    {"question": "کدام روش عملی برای تضمین مسئولیت پذیری (Accountability) در پروژه های AI توصیه می شود؟", "correct_answer": "مستندسازی کامل فرآیند توسعه و تصمیم گیری های مدل", "incorrect_answers": ["ایجاد تیمهای نظارتی مستقل برای بررسی عملکرد سیستم", "تعریف دقیق نقشها و مسئولیتها در تیم توسعه و بهره برداری", "استفاده از ابزارهای خودکار برای ثبت و گزارش عملکرد مدل "]},
    {"question": "در طراحی سیستمهای AI، کدام رویکرد به بهبود عدالت (Fairness) کمک می کند؟", "correct_answer": "ارزیابی مداوم مدل روی گروههای مختلف و اصلاح تبعیضها", "incorrect_answers": ["استفاده از معیارهای عدالت در فرایند آموزش و ارزیابی مدل", "بهینه سازی الگوریتم ها برای کاهش اثرات جانبی نامطلوب", "اعمال تنظیمات دستی برای توازن نتایج در گروه های مختلف"]},
    {"question": "چگونه میتوان از سوء استفاده احتمالی از مدلهای هوش مصنوعی جلوگیری کرد؟", "correct_answer": "محدود کردن دسترسی به مدل و اعمال سیاستهای امنیتی دقیق", "incorrect_answers": ["پیاده سازی مکانیزم های احراز هویت و کنترل دسترسی چندلایه", "نظارت مستمر بر رفتار مدل و شناسایی الگوهای غیر معمول ", "آموزش کاربران درباره استفاده مسئولانه از سیستم "]},
    {"question": "کدام اقدام عملی به بهبود قابلیت توضیح پذیری (Explainability) مدلهای AI کمک می کند؟", "correct_answer": "استفاده از مدلهای قابل تفسیر مانند درخت تصمیم یا مدلهای خطی ساده ", "incorrect_answers": ["توسعه ابزارهای بصری سازی برای نمایش فرآیند تصمیم گیری مدل ", "مستندسازی دقیق ساختار و پارامترهای مدل برای تحلیل بهتر ", "آموزش تیم توسعه برای فهم بهتر عملکرد مدل "]},
    {"question": "در توسعه سیستم های AI، چرا مشارکت ذینفعان مختلف اهمیت دارد؟", "correct_answer": "برای تضمین اینکه نگرانیها و نیازهای همه گروهها در نظر گرفته شود ", "incorrect_answers": ["برای افزایش شفافیت و پذیرش اجتماعی سیستم ", "برای بهبود کیفیت داده ها و بازخورد مستمر در طول توسعه ", "برای تسهیل هماهنگی بین تیم های فنی و غیر فنی "]},
    {"question": "برای ارزیابی اخلاقی یک پروژه هوش مصنوعی کدام روش عملی مؤثرتر است؟", "correct_answer": "انجام ارزیابیهای مستقل و مستمر با حضور متخصصان اخلاق و فناوری ", "incorrect_answers": ["استفاده از چارچوبهای استاندارد اخلاقی برای بررسی پروژه ", "دریافت بازخورد از کاربران نهایی و ذینفعان پروژه ", "مستندسازی کامل فرآیند توسعه و تصمیم گیری ها "]},

    // موضوع سیزدهم: ابزارها و فریمورکهای هوش مصنوعی
    {"question": "کدام ویژگی اصلی TensorFlow را از سایر فریمورکهای هوش مصنوعی متمایز می کند؟", "correct_answer": "قابلیت اجرای مدلها روی سخت افزارهای متنوع شامل GPU، CPU و TPU با پشتیبانی از محاسبات توزیع شده ", "incorrect_answers": ["تمرکز صرف بر یادگیری نظارت شده و عدم پشتیبانی کامل از یادگیری بدون نظارت ", "معماری گراف محاسباتی استاتیک که امکان بهینه سازی پیشرفته را فراهم میکند اما انعطاف پذیری کمتری نسبت به گرافهای پویا دارد ", "پشتیبانی محدود از مدلهای سفارشی و نیاز به استفاده از API های سطح پایین برای توسعه "]},
    {"question": "در PyTorch، چه ویژگی ای باعث سهولت در توسعه مدلهای پیچیده می شود؟", "correct_answer": "استفاده از گراف محاسباتی پویا (Dynamic Computation Graph) که امکان تغییر ساختار مدل در زمان اجرا را میدهد ", "incorrect_answers": ["معماری گراف محاسباتی استاتیک که به بهینه سازی بهتر مدل کمک میکند اما انعطاف پذیری کمتری دارد ", "محدودیت در استفاده از GPU برای تسریع محاسبات در نسخه های اولیه ", "عدم پشتیبانی کامل از توزیع آموزش مدل در محیط های چندگانه "]},
    {"question": "برای آموزش مدلهای بزرگ در محیطهای توزیع شده کدام فریمورک معمولاً ترجیح داده می شود؟", "correct_answer": "TensorFlow به دلیل پشتیبانی گسترده از آموزش توزیع شده، هماهنگی بین گره ها و ابزارهای مدیریت منابع ", "incorrect_answers": ["فریمورک های سبک مانند scikit-learn که برای آموزش مدلهای کوچک طراحی شده اند و قابلیت توزیع محدودی دارند ", "استفاده از فریمورکهایی که فقط روی CPU اجرا میشوند و از GPU پشتیبانی نمی کنند ", "ابزارهای غیر مرتبط با یادگیری ماشین که قابلیت پردازش موازی ندارند "]},
    {"question": "کدام ابزار برای مدیریت داده های بزرگ و پیش پردازش آنها در پروژه های هوش مصنوعی کاربردی است؟", "correct_answer": "Apache Spark به دلیل قابلیت پردازش توزیع شده، مقیاس پذیری بالا و ادغام با اکوسیستم یادگیری ماشین ", "incorrect_answers": ["ابزارهای محلی مانند Pandas که برای داده های کوچک مناسب اند ولی در مقیاس بزرگ محدودیت دارند ", "نرم افزارهای ویرایش متن که برای پردازش داده های حجیم مناسب نیستند ", "پایگاه های داده رابطه ای سنتی که قابلیت پردازش موازی داده های بزرگ را ندارند "]},
    {"question": "در انتخاب فریمورک برای پروژه هوش مصنوعی کدام عامل مهم تر است؟", "correct_answer": "سازگاری فریمورک با نیازهای پروژه، قابلیت توسعه آسان و پشتیبانی فعال جامعه کاربری ", "incorrect_answers": ["محبوبیت فریمورک بدون توجه به محدودیت های فنی پروژه ", "استفاده صرفاً از فریمورکهای جدید و کمتر تست شده به دلیل نوآوری ", "انتخاب فریمورک بر اساس توصیه های غیر تخصصی و بدون ارزیابی دقیق "]},
    {"question": "کدام ویژگی در Keras باعث تسهیل توسعه سریع مدلهای یادگیری عمیق می شود؟", "correct_answer": "رابط کاربری سطح بالا و ماژولار که امکان ساخت سریع مدلها را با حداقل کدنویسی فراهم میکند و روی TensorFlow اجرا می شود ", "incorrect_answers": ["نیاز به نوشتن کدهای پیچیده برای هر لایه مدل به منظور کنترل دقیق تر ", "عدم پشتیبانی از بهینه سازی مدل در زمان اجرا و نیاز به ابزارهای جانبی ", "محدودیت در انتخاب الگوریتمهای آموزش و عدم انعطاف پذیری "]},
    {"question": "برای ارزیابی عملکرد مدل در فریمورکهای هوش مصنوعی کدام ابزار کاربردی است؟", "correct_answer": "استفاده از کتابخانه های ارزیابی مانند scikit-learn که معیارهای دقیق و متنوعی برای سنجش دقت، یادآوری و F1-score ارائه می دهند ", "incorrect_answers": ["بررسی صرفا سرعت اجرای مدل بدون توجه به کیفیت پیش بینی ها ", "استفاده از داده های آموزشی برای ارزیابی که ممکن است منجر به بیش برازش شود ", "اعتماد کامل به نتایج اولیه بدون آزمونهای اعتبار سنجی "]},
    {"question": "کدام فریمورک برای توسعه سریع مدلهای یادگیری ماشین در زبان پایتون محبوب است؟", "correct_answer": "scikit-learn به دلیل سادگی، مستندسازی کامل و گستردگی الگوریتم های پایه و پیشرفته ", "incorrect_answers": ["MATLAB که بیشتر برای محاسبات عددی و مهندسی کاربرد دارد و پشتیبانی محدودی از یادگیری عمیق دارد ", "Java بدون کتابخانه های تخصصی یادگیری ماشین که توسعه را پیچیده می کند ", "++C که به دلیل پیچیدگی زبان برای توسعه سریع مناسب نیست مگر با کتابخانه های سطح بالا "]},
    {"question": "کدام رویکرد در فریمورکهای هوش مصنوعی به بهبود سرعت آموزش مدل کمک میکند؟", "correct_answer": "استفاده از پردازش موازی، بهینه سازی سخت افزاری مانند GPU و TPU و تکنیکهای کاهش دقت محاسباتی (Quantization) ", "incorrect_answers": ["کاهش تعداد داده های آموزشی که ممکن است منجر به کاهش دقت شود ", "اجرای مدل روی CPU بدون استفاده از سخت افزارهای تسریع کننده که سرعت را کاهش میدهد ", "افزایش تعداد لایه های مدل بدون بهینه سازی که موجب کندی میشود "]},
    {"question": "در پروژه های هوش مصنوعی چرا استفاده از ابزارهای مدیریت نسخه مدل اهمیت دارد؟", "correct_answer": "برای پیگیری تغییرات مدل، امکان بازگشت به نسخه های قبلی، تسهیل همکاری تیمی و تضمین تکرار پذیری نتایج ", "incorrect_answers": ["برای کاهش حجم داده های آموزشی که ارتباط مستقیمی با مدیریت نسخه ندارد ", "برای افزایش سرعت اجرای مدل که بیشتر به سخت افزار مرتبط است ", "برای حذف نیاز به مستندسازی پروژه که کاملاً نادرست است "]},

    // موضوع چهاردهم: پروژه های عملی هوش مصنوعی
    {"question": "در شروع یک پروژه عملی هوش مصنوعی بهترین گام اولیه چیست؟", "correct_answer": "تعريف دقيق مسئله و اهداف پروژه با توجه به نیازهای کسب و کار یا کاربرد نهایی ", "incorrect_answers": ["جمع آوری داده های اولیه و بررسی سریع کیفیت بدون تعیین دقیق اهداف ", "انتخاب مدلهای متنوع برای آزمایش بدون تحلیل مسئله ", "تمرکز بر پیاده سازی سریع بدون برنامه ریزی دقیق "]},
    {"question": "برای اطمینان از کیفیت داده ها در پروژه کدام اقدام عملی ضروری است؟", "correct_answer": "پاک سازی داده ها، حذف داده های ناقص و بررسی توزیع داده ها برای جلوگیری از تعصب ", "incorrect_answers": ["استفاده از داده های خام با حداقل تغییر برای حفظ اصالت داده ها ", "افزایش حجم داده ها بدون ارزیابی کیفیت و تنوع آنها ", "حذف داده های پرت بدون تحليل علت وجود آنها و تأثیر بر مدل "]},
    {"question": "در انتخاب مدل برای پروژه کدام معیار اهمیت بیشتری دارد؟", "correct_answer": "تناسب مدل با نوع داده ها و مسئله و تعادل بین دقت و پیچیدگی مدل ", "incorrect_answers": ["انتخاب مدلهای پیچیده تر برای پوشش تمامی جنبه ها بدون توجه به منابع ", "انتخاب مدل بر اساس محبوبیت در جامعه علمی بدون ارزیابی داده ها ", "استفاده از مدلهای ساده بدون بررسی عملکرد در داده های واقعی "]},
    {"question": "چگونه میتوان از بیش برازش (Overfitting) در پروژه جلوگیری کرد؟", "correct_answer": "استفاده از تکنیکهایی مانند Dropout، Cross-Validation و افزایش داده ها ", "incorrect_answers": ["کاهش تعداد داده های آموزشی برای ساده سازی مدل و جلوگیری از پیچیدگی ", "حذف لایه های نرمالیزاسیون برای کاهش پیچیدگی مدل ", "آموزش مدل فقط روی داده های آموزشی بدون ارزیابی عملکرد در داده های جدید "]},
    {"question": "در پروژه های عملی بهترین روش برای ارزیابی مدل چیست؟", "correct_answer": "استفاده از مجموعه داده های جداگانه برای تست و معیارهای دقیق مانند دقت، یادآوری و F1-Score ", "incorrect_answers": ["ارزیابی مدل فقط بر اساس داده های آموزشی برای سرعت بیشتر ", "اعتماد به نتایج اولیه بدون آزمونهای اعتبارسنجی تکمیلی ", "بررسی صرفاً سرعت اجرای مدل بدون توجه به کیفیت پیش بینی ها "]},
    {"question": "در پروژه های عملی چگونه میتوان عملکرد مدل را بهبود داد؟", "correct_answer": "فاین تونینگ مدل با داده های جدید و بهینه سازی پارامترها ", "incorrect_answers": ["استفاده از مدلهای پیش فرض بدون تغییر برای کاهش ریسک ", "کاهش تعداد لایه های مدل برای افزایش سرعت اجرا ", "حذف داده های آموزشی برای کاهش حجم و زمان آموزش "]},
    {"question": "کدام ابزار برای مدیریت نسخه های مدل و همکاری تیمی در پروژه های عملی مناسب است؟", "correct_answer": "استفاده از سیستمهای کنترل نسخه مانند Git و پلتفرم های همکاری آنلاین ", "incorrect_answers": ["ذخیره مدلها در پوشه های محلی بدون مستندسازی تغییرات ", "ارسال مدلها به صورت ایمیل بدون ثبت نسخه ها ", "استفاده از فایلهای متنی ساده بدون ساختار برای مستندسازی "]},
    {"question": "برای به اشتراک گذاری نتایج پروژه با ذینفعان کدام روش عملی مناسب تر است؟", "correct_answer": "تهیه گزارشهای جامع شامل تحلیل داده ها، عملکرد مدل و پیشنهادات بهبود ", "incorrect_answers": ["ارسال خروجیهای خام مدل بدون توضيح يا تحليل ", "ارائه فقط کدهای برنامه نویسی بدون مستندسازی فرآیند ", "عدم اشتراک گذاری نتایج تا پایان کامل پروژه "]},
    {"question": "در مواجهه با مشکلات فنی در پروژه بهترین رویکرد چیست؟", "correct_answer": "تحلیل دقیق مشکل، استفاده از منابع معتبر و مشورت با تیم برای حل مسئله ", "incorrect_answers": ["نادیده گرفتن مشکل و ادامه کار با فرض عدم تأثیر آن ", "تغییر سریع مدل بدون بررسی علت اصلی خطا ", "حذف بخشهای مشکل دار بدون جایگزینی یا اصلاح "]},
    {"question": "برای تضمین موفقیت پروژه هوش مصنوعی کدام عامل کلیدی است؟", "correct_answer": "برنامه ریزی دقیق، مدیریت منابع، ارزیابی مستمر و تطبیق با نیازهای واقعی ", "incorrect_answers": ["تمرکز صرف بر توسعه مدل بدون توجه به کاربرد عملی و بازخورد کاربران ", "استفاده از داده های محدود برای کاهش هزینه ها و زمان پروژه ", "اجرای پروژه بدون دریافت بازخورد از کاربران نهایی و ذینفعان "]},

    // موضوع پانزدهم: بهینه سازی مدلهای هوش مصنوعی
    {"question": "در بهینه سازی مدلهای هوش مصنوعی کدام روش برای کاهش خطای مدل و بهبود دقت کاربردی تر است؟", "correct_answer": "تنظیم دقیق هایپرپارامترها مانند نرخ یادگیری، تعداد لایه ها و اندازه دسته (batch size) با ارزیابی مستمر ", "incorrect_answers": ["افزایش تعداد داده های آموزشی بدون تغییر در ساختار مدل و بدون ارزیابی تأثیر آن ", "کاهش تعداد لایه ها برای ساده سازی مدل بدون بررسی تأثیر بر دقت ", "استفاده از مدلهای پیش فرض بدون تنظیم های اختصاصی و بهینه سازی "]},
    {"question": "کدام تکنیک میتواند به جلوگیری از بیش برازش (Overfitting) در مدل کمک کند؟", "correct_answer": "استفاده از روشهایی مانند Early Stopping، Dropout و افزایش داده ها با ارزیابی مداوم عملکرد ", "incorrect_answers": ["کاهش تعداد داده های آموزشی برای ساده سازی مدل که ممکن است منجر به کاهش تعمیم پذیری شود ", "افزایش تعداد پارامترهای مدل بدون کنترل که ممکن است باعث بیش برازش شود ", "حذف لایه های نرمالیزاسیون که میتواند پایداری آموزش را کاهش دهد "]},
    {"question": "در بهینه سازی مدل چرا تنظیم نرخ یادگیری (Learning Rate) اهمیت دارد؟", "correct_answer": "نرخ یادگیری مناسب باعث تعادل بین سرعت همگرایی و پایداری آموزش میشود و از نوسانات جلوگیری می کند ", "incorrect_answers": ["نرخ یادگیری بالا همیشه منجر به آموزش سریع تر و بهتر میشود هرچند ممکن است ناپایداری ایجاد کند ", "نرخ یادگیری پایین باعث افزایش سرعت آموزش میشود اما ممکن است به همگرایی نرسد ", "نرخ یادگیری تاثیری بر عملکرد مدل ندارد و تنها پارامتر کمکی است "]},
    {"question": "کدام روش برای بهبود سرعت آموزش مدلهای بزرگ در سخت افزارهای محدود مناسب تر است؟", "correct_answer": "استفاده از تکنیکهای کمینه سازی مدل مانند Quantization و Pruning با حفظ دقت قابل قبول ", "incorrect_answers": ["افزایش حجم داده های ورودی برای بهبود دقت که ممکن است سرعت را کاهش دهد ", "اجرای مدل روی CPU بدون استفاده از GPU که معمولاً کندتر است ", "افزایش تعداد لایه ها بدون بهینه سازی که باعث کندی میشود "]},
    {"question": "در فرآیند بهینه سازی کدام معیار برای ارزیابی عملکرد مدل در مسائل طبقه بندی کاربردی است؟", "correct_answer": "معیارهایی مانند دقت (Accuracy)، یادآوری (Recall)، دقت مثبت پیش بینی شده (Precision) و F1-Score با توجه به نوع مسئله ", "incorrect_answers": ["صرفاً سرعت اجرای مدل بدون توجه به کیفیت پیش بینی ها که ممکن است گمراه کننده باشد ", "حجم داده های آموزشی استفاده شده که معیار عملکرد نیست ", "تعداد پارامترهای مدل که به تنهایی نشان دهنده کیفیت نیست "]},
    {"question": "کدام تکنیک به بهبود تعمیم پذیری مدل کمک میکند؟", "correct_answer": "استفاده از داده های متنوع و تکنیکهای منظم سازی (Regularization) مانند L1/L2 و Dropout ", "incorrect_answers": ["کاهش تعداد داده های آموزشی که ممکن است باعث کاهش قابلیت تعمیم شود ", "افزایش تعداد لایه ها بدون مدیریت مناسب که ممکن است بیش برازش ایجاد کند ", "حذف داده های پرت بدون تحلیل اثر آنها که گاهی داده های مهم حذف میشوند "]},
    {"question": "چرا استفاده از Cross Validation در بهینه سازی مدل اهمیت دارد؟", "correct_answer": "برای ارزیابی دقیق تر عملکرد مدل و کاهش احتمال بیش برازش با تقسیم داده ها به چند بخش", "incorrect_answers": ["برای افزایش سرعت آموزش مدل که معمولاً باعث افزایش زمان میشود ", "برای کاهش حجم داده های آموزشی که هدف آن نیست ", "برای ساده سازی مدل بدون ارزیابی که نادرست است "]},
    {"question": "در بهینه سازی مدل کدام روش برای انتخاب بهترین هایپرپارامترها کاربرد دارد؟", "correct_answer": "جستجوی شبکه ای (Grid Search) و جستجوی تصادفی (Random Search) با ارزیابی عملکرد مدل", "incorrect_answers": ["انتخاب تصادفی هایپر پارامترها بدون ارزیابی که ممکن است منجر به نتایج ضعیف شود", "استفاده از تنظیمات پیش فرض بدون تغییر که ممکن است بهینه نباشند", "افزایش تعداد لایه ها برای بهبود خودکار که تضمینی نیست"]},
    {"question": "چگونه میتوان از مشکلات ناپدید شدن یا انفجار گرادیان در مدلهای عمیق جلوگیری کرد؟", "correct_answer": "استفاده از توابع فعال سازی مناسب مانند ReLU، نرمال سازی Batch و الگوریتم های بهینه سازی پیشرفته ", "incorrect_answers": ["افزایش نرخ یادگیری به مقدار زیاد که ممکن است باعث ناپایداری شود ", "کاهش تعداد داده های آموزشی که تأثیری بر این مشکل ندارد ", "حذف لایه های پنهان که ممکن است مدل را ضعیف کند "]},
    {"question": "برای بهبود عملکرد مدل در داده های جدید و ناشناخته کدام روش مناسب تر است؟", "correct_answer": "استفاده از تکنیکهای یادگیری انتقالی (Transfer Learning) و فاین تونینگ با داده های هدف ", "incorrect_answers": ["آموزش مدل فقط روی داده های قدیمی بدون به روز رسانی که ممکن است تعمیم پذیری را کاهش دهد ", "کاهش تعداد داده های آموزشی برای تمرکز بر داده های اصلی که ممکن است مضر باشد ", "استفاده از مدلهای ساده بدون تنظیمات اختصاصی که ممکن است کافی نباشد "]}
];

    // دریافت عناصر از DOM
    const startScreen = document.getElementById('start-screen');
    const quizScreen = document.getElementById('quiz-screen');
    const resultScreen = document.getElementById('result-screen');
    const startBtn = document.getElementById('start-btn');
    const nextBtn = document.getElementById('next-btn');
    const restartBtn = document.getElementById('restart-btn');
    const questionText = document.getElementById('question-text');
    const answersContainer = document.getElementById('answers-container');
    const timerEl = document.getElementById('timer');
    const progressEl = document.getElementById('progress');

    // متغیرهای وضعیت آزمون
    let shuffledQuestions, currentQuestionIndex, score, timerInterval;
    const totalQuestionsInTest = 20;
    const timeLimit = 20 * 60; // 20 دقیقه به ثانیه

    function startQuiz() {
        startScreen.classList.add('hidden');
        resultScreen.classList.add('hidden');
        quizScreen.classList.remove('hidden');
        nextBtn.classList.add('hidden');

        shuffledQuestions = quizData.sort(() => Math.random() - 0.5).slice(0, totalQuestionsInTest);
        currentQuestionIndex = 0;
        score = 0;

        clearInterval(timerInterval);
        startTimer();
        setNextQuestion();
    }

    function setNextQuestion() {
        resetState();
        showQuestion(shuffledQuestions[currentQuestionIndex]);
    }

    function showQuestion(question) {
        progressEl.innerText = `سوال ${currentQuestionIndex + 1} از ${totalQuestionsInTest}`;
        questionText.innerText = question.question;

        const answers = [...question.incorrect_answers, question.correct_answer];
        answers.sort(() => Math.random() - 0.5);

        answers.forEach(answer => {
            const button = document.createElement('button');
            button.innerText = answer;
            button.classList.add('answer-btn');
            if (answer === question.correct_answer) {
                button.dataset.correct = true;
            }
            button.addEventListener('click', selectAnswer);
            answersContainer.appendChild(button);
        });
    }

    function resetState() {
        nextBtn.classList.add('hidden');
        while (answersContainer.firstChild) {
            answersContainer.removeChild(answersContainer.firstChild);
        }
    }

    function selectAnswer(e) {
        const selectedBtn = e.target;
        const correct = selectedBtn.dataset.correct === 'true';

        if (correct) {
            score++;
        }

        Array.from(answersContainer.children).forEach(button => {
            if (button.dataset.correct === 'true') {
                button.classList.add('correct');
            } else {
                button.classList.add('incorrect');
            }
            button.disabled = true;
        });

        // **منطق اصلاح شده برای پایان آزمون**
        // اگر این آخرین سوال نیست، دکمه "سوال بعدی" را نشان بده
        if (currentQuestionIndex < totalQuestionsInTest - 1) {
            nextBtn.classList.remove('hidden');
        } else {
            // اگر آخرین سوال است، بعد از 1.5 ثانیه نتایج را نمایش بده
            setTimeout(showResults, 1500);
        }
    }
    
    function handleNextButton() {
        currentQuestionIndex++;
        setNextQuestion();
    }

    function showResults() {
        clearInterval(timerInterval);
        quizScreen.classList.add('hidden');
        resultScreen.classList.remove('hidden');

        const correctCount = score;
        const incorrectCount = totalQuestionsInTest - score;
        const percentage = (score / totalQuestionsInTest) * 100;

        document.getElementById('score-correct').innerText = correctCount;
        document.getElementById('score-incorrect').innerText = incorrectCount;
        document.getElementById('score-percentage').innerText = percentage.toFixed(1);
    }

    function startTimer() {
        let timeLeft = timeLimit;
        timerEl.innerText = `${Math.floor(timeLeft / 60)}:00`;

        timerInterval = setInterval(() => {
            timeLeft--;
            const minutes = Math.floor(timeLeft / 60);
            const seconds = timeLeft % 60;
            timerEl.innerText = `${minutes}:${seconds < 10 ? '0' : ''}${seconds}`;

            if (timeLeft <= 0) {
                clearInterval(timerInterval);
                showResults();
            }
        }, 1000);
    }

    // افزودن Event Listener ها
    startBtn.addEventListener('click', startQuiz);
    nextBtn.addEventListener('click', handleNextButton);
    restartBtn.addEventListener('click', startQuiz);
});
